{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[],"collapsed_sections":["vcA7TWK6Z99y","e1yx22PAX1ko","udQmmT5MYuCK","X3gbdM02VdNt"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup: Mount Drive, Install Dependencies & Import Libraries"],"metadata":{"id":"vcA7TWK6Z99y"},"id":"vcA7TWK6Z99y"},{"cell_type":"code","source":["#Setup: Mount Drive, Install Dependencies & Import Libraries (One Per Line)** { display-mode: \"form\" }\n","#@markdown\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!apt update -y\n","!apt install -y ffmpeg\n","!apt install -y aria2\n","!apt install -y wget\n","\n","!pip install -q -U yt-dlp\n","!pip install -q -U ipywidgets\n","!pip install -q -U requests\n","!pip install -q -U beautifulsoup4\n","!pip install -q -U python-magic\n","!pip install -q -U m3u8downloader\n","\n","import os\n","import subprocess\n","import shlex\n","import re\n","import shutil\n","import time\n","import json\n","import mimetypes\n","import magic\n","import requests\n","from yt_dlp import YoutubeDL\n","from IPython.display import display\n","from IPython.display import HTML\n","from ipywidgets import IntProgress\n","from zipfile import ZipFile\n","from bs4 import BeautifulSoup\n","from urllib.parse import urlparse\n","from urllib.parse import unquote\n"],"metadata":{"id":"hMtuuphvVXFB","cellView":"form"},"id":"hMtuuphvVXFB","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Compress Video"],"metadata":{"id":"e1yx22PAX1ko"},"id":"e1yx22PAX1ko"},{"cell_type":"code","execution_count":null,"id":"44e32e49","metadata":{"cellView":"form","id":"44e32e49"},"outputs":[],"source":["# Compress Video (with Progress Bar)** { display-mode: \"form\" }\n","video_path = \"/content/input.mp4\"  #@param {type:\"string\"}\n","output_path = \"/content/output_compressed.mp4\"  #@param {type:\"string\"}\n","crf = \"23\"  #@param {type:\"string\"}\n","\n","if not os.path.exists(video_path):\n","    print(f\"🔴 Error: Input video path does not exist: {video_path}\")\n","else:\n","    cmd_probe = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{video_path}\"'\n","    try:\n","        duration = float(subprocess.check_output(shlex.split(cmd_probe)))\n","        bar = IntProgress(min=0, max=100, description=\"Compressing:\")\n","        display(bar)\n","\n","        output_dir_compress = os.path.dirname(output_path)\n","        if output_dir_compress and not os.path.exists(output_dir_compress):\n","            os.makedirs(output_dir_compress, exist_ok=True)\n","\n","        cmd = f'ffmpeg -i \"{video_path}\" -vcodec libx264 -crf {crf} \"{output_path}\" -progress pipe:1 -nostats -y'\n","        print(f\"Executing: {cmd}\")\n","        proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace')\n","\n","        for line in proc.stdout:\n","            # print(line, end='') # Uncomment for detailed ffmpeg output\n","            m = re.search(r'out_time_ms=(\\d+)', line)\n","            if m:\n","                t = int(m.group(1)) / 1_000_000.0\n","                if duration > 0:\n","                    pct = min(100, int((t / duration) * 100))\n","                    bar.value = pct\n","\n","        proc.wait()\n","        if proc.returncode == 0:\n","            bar.value = 100\n","            print(\"\\n✅ Compression complete.\")\n","        else:\n","            bar.bar_style = 'danger'\n","            bar.value = 0 # Reset or indicate failure\n","            print(f\"\\n🔴 Compression failed. FFmpeg Error Code: {proc.returncode}\")\n","            # To see full error, you might need to capture stderr separately if not merged into stdout\n","    except FileNotFoundError:\n","        print(\"🔴 Error: ffprobe or ffmpeg not found. Ensure they are installed and in PATH.\")\n","    except ValueError:\n","        print(\"🔴 Error: Could not determine video duration. Is ffprobe working correctly and is the video file valid?\")\n","    except Exception as e:\n","        print(f\"🔴 An unexpected error occurred during compression: {e}\")"]},{"cell_type":"markdown","source":["# File Manager"],"metadata":{"id":"udQmmT5MYuCK"},"id":"udQmmT5MYuCK"},{"cell_type":"code","execution_count":null,"id":"5d436260","metadata":{"cellView":"form","id":"5d436260"},"outputs":[],"source":["# File Manager (with Progress Bar)** { display-mode: \"form\" }\n","operation = \"move\"  #@param [\"move\",\"delete\",\"copy\"] {type:\"string\"}\n","source_path = \"/content/drive/MyDrive/source_folder\"  #@param {type:\"string\"}\n","dest_path = \"/content/drive/MyDrive/destination_folder\"  #@param {type:\"string\"}\n","\n","files_to_process = []\n","if not os.path.exists(source_path):\n","    print(f\"🔴 Error: Source path does not exist: {source_path}\")\n","elif operation in [\"move\", \"copy\"] and not dest_path:\n","    print(f\"🔴 Error: Destination path is required for {operation} operation.\")\n","else:\n","    if operation == \"move\" or operation == \"copy\":\n","        for root, dirs, fs in os.walk(source_path):\n","            for f_name in fs:\n","                src_file = os.path.join(root, f_name)\n","                # Create the destination path by appending the relative path from source_path to dest_path\n","                relative_path_to_file = os.path.relpath(src_file, source_path)\n","                dst_file = os.path.join(dest_path, relative_path_to_file)\n","                files_to_process.append((src_file, dst_file))\n","    elif operation == \"delete\":\n","        for root, dirs, fs in os.walk(source_path, topdown=False): # topdown=False for deleting files first\n","            for f_name in fs:\n","                files_to_process.append(os.path.join(root, f_name))\n","            for d_name in dirs:\n","                 files_to_process.append(os.path.join(root, d_name)) # Add directories to delete after their contents\n","        if os.path.isdir(source_path): # Ensure the source_path itself is added if it's a directory and delete is chosen\n","             files_to_process.append(source_path)\n","\n","    if not files_to_process and operation != \"delete\": # For delete, source_path itself might be the only item if empty\n","        print(f\"No files found in source path: {source_path} to {operation}\")\n","    else:\n","        bar = IntProgress(min=0, max=len(files_to_process) if files_to_process else 1, description=operation.title()+\":\")\n","        display(bar)\n","        processed_count = 0\n","        for idx, item in enumerate(files_to_process, 1):\n","            try:\n","                if operation == \"move\":\n","                    src, dst = item\n","                    os.makedirs(os.path.dirname(dst), exist_ok=True)\n","                    shutil.move(src, dst)\n","                elif operation == \"copy\":\n","                    src, dst = item\n","                    os.makedirs(os.path.dirname(dst), exist_ok=True)\n","                    shutil.copy2(src, dst) # copy2 preserves metadata\n","                elif operation == \"delete\":\n","                    path_to_delete = item\n","                    if os.path.isdir(path_to_delete):\n","                        shutil.rmtree(path_to_delete, ignore_errors=False) # ignore_errors=False to catch issues\n","                    elif os.path.isfile(path_to_delete):\n","                        os.remove(path_to_delete)\n","                processed_count +=1\n","            except Exception as e:\n","                print(f\"\\n🔴 Error {operation}ing {item}: {e}\")\n","            bar.value = idx\n","\n","        bar.value = bar.max # Ensure bar is full on completion\n","        print(f\"\\n✅ {operation.title()} complete. Processed {processed_count} items.\")"]},{"cell_type":"markdown","source":["# Universal Downloader"],"metadata":{"id":"X3gbdM02VdNt"},"id":"X3gbdM02VdNt"},{"cell_type":"code","source":["# Run to Download\n","# Description: Define the URL, download type, and output path here.\n","# Error handling for the output path is included.\n","# Input Parameters\n","url = \"https://kebab.bunkr.ru/1e02c98e-c67a-4409-85e7-1bad235eb445.mp4\" #@param {type:\"string\"}\n","download_type = \"d\" #@param [\"a\", \"b\", \"c\", \"d\"] {allow-input: true}\n","output_path = \"/content/drive/MyDrive/Downloads\" #@param {type:\"string\"}\n","\n","# Error handling for output_path\n","if not output_path:\n","    print(\"Error: Output path cannot be empty. Using default: /content/downloads\")\n","    output_path = \"/content/downloads\"\n","\n","if not os.path.exists(output_path):\n","    try:\n","        os.makedirs(output_path, exist_ok=True)\n","        print(f\"Output directory created: {output_path}\")\n","    except OSError as e:\n","        print(f\"Error creating output directory {output_path}: {e}. Please check the path and permissions.\")\n","        # Optionally, you might want to stop execution or use a fallback\n","        output_path = \"/content/downloads\" # Fallback to a default if creation fails\n","        if not os.path.exists(output_path):\n","             os.makedirs(output_path, exist_ok=True) # Try creating default\n","        print(f\"Using fallback output directory: {output_path}\")\n","elif not os.path.isdir(output_path):\n","    print(f\"Error: The specified output path '{output_path}' is a file, not a directory. Please provide a valid directory path.\")\n","    # Optionally, you might want to stop execution or use a fallback\n","    output_path = \"/content/downloads\" # Fallback\n","    if not os.path.exists(output_path):\n","         os.makedirs(output_path, exist_ok=True)\n","    print(f\"Using fallback output directory: {output_path}\")\n","else:\n","    print(f\"Using output directory: {output_path}\")\n","\n","# Further ensure the output path ends with a separator if it's a directory for file concatenation\n","if not output_path.endswith(os.sep):\n","    output_path += os.sep\n","\n","print(f\"URL: {url}\")\n","print(f\"Download Type: {download_type}\")\n","print(f\"Output Path: {output_path}\")\n","\n"],"metadata":{"cellView":"form","id":"Sg6BhyBxVmqh"},"id":"Sg6BhyBxVmqh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown <font size=2.5>Run Cell to Start Download\n","# Description: This cell contains the consolidated download functions and\n","# executes the download based on the 'download_type' from Cell 2.\n","\n","# --- Consolidated Download Functions ---\n","\n","# Function a: wget Downloader\n","def download_with_wget(file_url, save_location):\n","    print(f\"Starting wget download for: {file_url}\")\n","    try:\n","        # Ensure the save_location is a directory\n","        if not os.path.isdir(save_location):\n","             # Attempt to create if it doesn't exist, or raise error\n","            os.makedirs(save_location, exist_ok=True)\n","            print(f\"Created directory for wget: {save_location}\")\n","\n","        command = f'wget -P \"{save_location}\" \"{file_url}\"'\n","        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","        stdout, stderr = process.communicate()\n","\n","        if process.returncode == 0:\n","            print(\"wget download successful!\")\n","            # Try to find the downloaded filename (wget doesn't easily return it)\n","            # This is a basic way; more robust parsing of stdout might be needed\n","            lines = stdout.decode().splitlines() + stderr.decode().splitlines()\n","            saved_file_line = next((line for line in lines if \" saved [\" in line or \" -> \" in line or \"Saving to: ‘\" in line), None) #\n","            if saved_file_line:\n","                # Extract filename, this is highly dependent on wget output format\n","                match = re.search(r\"(?:Saving to: ‘|-> ‘)([^’]+)\", saved_file_line) #\n","                if match:\n","                    filename = os.path.basename(match.group(1).strip('‘’'))\n","                    print(f\"File saved as: {os.path.join(save_location, filename)}\")\n","                else:\n","                    print(f\"File saved in: {save_location}. Could not determine exact filename from output.\")\n","            else:\n","                print(f\"File saved in: {save_location}. Could not determine exact filename from output.\")\n","\n","        else:\n","            print(\"wget download failed.\")\n","            print(f\"Stderr: {stderr.decode()}\")\n","            print(f\"Stdout: {stdout.decode()}\")\n","    except Exception as e:\n","        print(f\"An error occurred during wget download: {e}\")\n","\n","# --- Functions for Bunkr Downloader (Type 'b') ---\n","def extract_id_from_url_bunkr(url): #\n","    album_pattern = r'https?://(?:bunkr|bunkrr)\\.(?:is|cr|ru|to|la|se)/a/(\\w+)' #\n","    album_match = re.match(album_pattern, url) #\n","    if album_match: #\n","        return {'type': 'album', 'id': album_match.group(1)} #\n","\n","    file_pattern = r'https?://(?:bunkr|bunkrr)\\.(?:is|cr|ru|to|la|se)/(?:[dfvi])/([^/]+)' #\n","    file_match = re.match(file_pattern, url) #\n","    if file_match: #\n","        return {'type': 'file', 'id': file_match.group(1)} #\n","\n","    cache_pattern = r'https?://(?:soup\\.bunkr\\.(?:se|is|cr|ru|to|la)|c\\.bunkr-cache\\.se|cdn[0-9]*\\.bunkr\\.(?:is|cr|ru|to|la))/([^/]+)/([^?]+)' #\n","    cache_match = re.match(cache_pattern, url) #\n","    if cache_match: #\n","        return {'type': 'direct', 'id': cache_match.group(2)} #\n","\n","    raise ValueError(\"Invalid Bunkr URL format. Expected formats:\\n- Album: https://bunkr.ru/a/ALBUMID\\n- File: https://bunkr.ru/[d|f|v|i]/FILEID\\n- Direct: https://c.bunkr-cache.se/*/FILENAME or https://soup.bunkr.ru/*/FILENAME\") #\n","\n","def verify_video_content_bunkr(file_path): #\n","    try:\n","        mime = magic.Magic(mime=True) #\n","        file_type = mime.from_file(file_path) #\n","        if file_type.startswith('video/'): #\n","            print(f\"✅ Verified as valid video file: {file_type}\") #\n","            return True #\n","        elif file_type in ['text/html', 'image/png', 'image/jpeg', 'image/gif']: #\n","            print(f\"❌ Download failed - received {file_type} instead of video\") #\n","            return False #\n","        else:\n","            file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB #\n","            if file_size < 0.5: #\n","                print(f\"❌ File too small ({file_size:.2f} MB) - likely not a video\") #\n","                return False #\n","            else:\n","                print(f\"⚠️ Unrecognized file type: {file_type}, but size seems appropriate ({file_size:.2f} MB)\") #\n","                return True #\n","    except Exception as e: #\n","        print(f\"Error verifying file content: {e}\") #\n","        return False #\n","\n","def get_direct_download_url_bunkr(viewer_url, headers): #\n","    try:\n","        print(f\"Processing viewer page: {viewer_url}\") #\n","        user_agents = [ #\n","            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', #\n","            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15', #\n","            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36' #\n","        ]\n","        download_url = None #\n","        for agent in user_agents: #\n","            headers['User-Agent'] = agent #\n","            response = requests.get(viewer_url, headers=headers) #\n","            if response.status_code != 200: #\n","                print(f\"Failed to access file viewer with agent {agent}: Status code {response.status_code}\") #\n","                continue #\n","            soup = BeautifulSoup(response.text, 'html.parser') #\n","            if \"geo restriction\" in response.text.lower() or \"content unavailable\" in response.text.lower(): #\n","                 print(\"⚠️ Detected geo-restriction or content unavailable message\") #\n","                 continue #\n","            for script in soup.find_all('script'): #\n","                if script.string: #\n","                    url_match = re.search(r'(?:streamUrl|downloadUrl|mediaUrl|src)[\"\\']\\s*:\\s*[\"\\']([^\"\\']+)[\"\\']', script.string) #\n","                    if url_match: #\n","                        download_url = url_match.group(1).replace('\\\\', '') #\n","                        break #\n","                    file_match = re.search(r'(https?://[^\"\\']*(?:\\.mp4|\\.webm|\\.mov|\\.avi|\\.mkv))', script.string) #\n","                    if file_match: #\n","                        download_url = file_match.group(1) #\n","                        break #\n","            if not download_url: #\n","                media_elem = soup.find('video') #\n","                if media_elem: #\n","                    source = media_elem.find('source') #\n","                    download_url = source.get('src') if source else media_elem.get('src') #\n","            if not download_url: #\n","                download_btn = soup.select_one('a.download-btn, a[download], a.download-link') #\n","                if download_btn: #\n","                    download_url = download_btn.get('href') #\n","            if download_url: #\n","                if not download_url.startswith('http'): #\n","                    base_url = urlparse(viewer_url) #\n","                    domain = f\"{base_url.scheme}://{base_url.netloc}\" #\n","                    download_url = f\"{domain}{download_url}\" #\n","                print(f\"Extracted direct download URL: {download_url}\") #\n","                if not any(ext in download_url.lower() for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                    print(\"⚠️ URL doesn't appear to be a video file. Will verify after download.\") #\n","                return download_url #\n","        if not download_url: #\n","            print(\"Could not find direct download URL - likely geo-restricted or content unavailable\") #\n","            return None #\n","    except Exception as e: #\n","        print(f\"Failed to process viewer page: {e}\") #\n","        return None #\n","\n","def extract_filename_from_url_bunkr(url): #\n","    parsed_url = urlparse(url) #\n","    path = parsed_url.path #\n","    filename = os.path.basename(path) #\n","    if parsed_url.query: #\n","        query_params = parsed_url.query.split('&') #\n","        for param in query_params: #\n","            if param.startswith('n='): #\n","                query_filename = param[2:] #\n","                if query_filename: #\n","                    filename = unquote(query_filename) #\n","                    break #\n","    if not any(filename.lower().endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","        if '.mp4' in url.lower(): #\n","            filename += '.mp4' #\n","        elif '.webm' in url.lower(): #\n","            filename += '.webm' #\n","        elif '.mov' in url.lower(): #\n","            filename += '.mov' #\n","        else: #\n","            filename += '.mp4' #\n","    return unquote(filename) #\n","\n","def download_file_bunkr(file_url, file_name, download_path, headers): #\n","    try:\n","        try:\n","            head_response = requests.head(file_url, headers=headers, timeout=10) #\n","            file_size = int(head_response.headers.get('content-length', 0)) / (1024 * 1024) #\n","            content_type = head_response.headers.get('content-type', '') #\n","            if content_type and 'video' not in content_type and 'octet-stream' not in content_type: #\n","                print(f\"⚠️ Content-Type '{content_type}' doesn't appear to be video. Will verify after download.\") #\n","            print(f\"File size: {file_size:.2f} MB\") #\n","            if file_size < 0.5: #\n","                print(\"⚠️ File seems too small for a video. Proceeding anyway but will verify.\") #\n","        except Exception as e: #\n","            print(f\"Could not determine file information: {e}\") #\n","        file_name = re.sub(r'[\\\\/*?:\"<>|]', \"_\", file_name) #\n","        file_path = os.path.join(download_path, file_name) #\n","        successful = False #\n","        retry_count = 0 #\n","        while not successful and retry_count < 3: #\n","            try:\n","                response = requests.get(file_url, headers=headers, stream=True, timeout=30) #\n","                if response.status_code != 200: #\n","                    print(f\"Failed to download {file_name}: Status code {response.status_code}\") #\n","                    retry_count += 1 #\n","                    time.sleep(2) #\n","                    continue #\n","                with open(file_path, 'wb') as f: #\n","                    total_length = int(response.headers.get('content-length', 0)) #\n","                    dl = 0 #\n","                    for chunk in response.iter_content(chunk_size=8192): #\n","                        if chunk: #\n","                            dl += len(chunk) #\n","                            f.write(chunk) #\n","                            done = int(50 * dl / total_length) if total_length > 0 else 0 #\n","                            print(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl*100/total_length:.2f}%\" if total_length > 0 else f\"\\r{dl/1024/1024:.2f} MB downloaded\", end='') #\n","                    print() #\n","                if verify_video_content_bunkr(file_path): #\n","                    print(f\"✅ Successfully downloaded {file_name}\") #\n","                    successful = True #\n","                else: #\n","                    print(f\"❌ Downloaded file is not a valid video. Removing and retrying...\") #\n","                    os.remove(file_path) #\n","                    retry_count += 1 #\n","                    time.sleep(2) #\n","            except Exception as e: #\n","                print(f\"Download attempt {retry_count + 1} failed: {e}\") #\n","                retry_count += 1 #\n","                time.sleep(2) #\n","        return successful #\n","    except Exception as e: #\n","        print(f\"An error occurred while downloading {file_name}: {e}\") #\n","        return False #\n","\n","def process_single_file_bunkr(file_url, headers, download_path): #\n","    try:\n","        file_url = re.sub(r'https?://(?:bunkr|bunkrr)\\.(?:is|cr|ru|to|la|se)', 'https://bunkr.ru', file_url) #\n","        if '/f/' in file_url: #\n","            file_name = extract_filename_from_url_bunkr(file_url) #\n","            return download_file_bunkr(file_url, file_name, download_path, headers) #\n","        download_url = get_direct_download_url_bunkr(file_url, headers) #\n","        if download_url: #\n","            file_name = extract_filename_from_url_bunkr(download_url) #\n","            return download_file_bunkr(download_url, file_name, download_path, headers) #\n","        return False #\n","    except Exception as e: #\n","        print(f\"Error processing single file: {e}\") #\n","        return False #\n","\n","def process_direct_cache_url_bunkr(url, headers, download_path): #\n","    try: #\n","        file_name = extract_filename_from_url_bunkr(url) #\n","        print(f\"Downloading direct cache file: {file_name}\") #\n","        if not any(ext in url.lower() for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","            print(\"⚠️ URL doesn't appear to be a video file. Checking content type...\") #\n","            try: #\n","                head_response = requests.head(url, headers=headers, timeout=10) #\n","                content_type = head_response.headers.get('content-type', '') #\n","                if 'video' not in content_type and 'octet-stream' not in content_type: #\n","                    print(f\"⚠️ Content-Type '{content_type}' doesn't appear to be video. Will verify after download.\") #\n","            except Exception as e: #\n","                print(f\"Could not check content type: {e}\") #\n","        return download_file_bunkr(url, file_name, download_path, headers) #\n","    except Exception as e: #\n","        print(f\"Error processing direct cache URL: {e}\") #\n","        return False #\n","\n","def download_bunkr_content_custom(url, custom_download_path): #\n","    try: #\n","        download_path = custom_download_path if custom_download_path else '/content/bunkr_downloads' #\n","        if not os.path.exists(download_path): #\n","            os.makedirs(download_path, exist_ok=True) #\n","            print(f\"Created download directory: {download_path}\") #\n","        else: #\n","            print(f\"Using existing download directory: {download_path}\") #\n","        try: #\n","            url_info = extract_id_from_url_bunkr(url) #\n","            content_type = url_info['type'] #\n","            content_id = url_info['id'] #\n","            print(f\"Content type: {content_type}, ID: {content_id}\") #\n","        except ValueError as e: #\n","            print(str(e)) #\n","            return #\n","        headers = { #\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', #\n","            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', #\n","            'Accept-Language': 'en-US,en;q=0.5', #\n","            'Referer': 'https://bunkr.ru/', #\n","            'DNT': '1', #\n","            'Connection': 'keep-alive', #\n","            'Upgrade-Insecure-Requests': '1', #\n","            'Sec-Fetch-Dest': 'document', #\n","            'Sec-Fetch-Mode': 'navigate', #\n","            'Sec-Fetch-Site': 'same-origin', #\n","            'Sec-Fetch-User': '?1', #\n","            'Cache-Control': 'max-age=0', #\n","        }\n","        if content_type == 'direct': #\n","            print(\"Processing direct cache URL...\") #\n","            success = process_direct_cache_url_bunkr(url, headers, download_path) #\n","            if success: #\n","                print(\"\\nFile download completed!\") #\n","                print(f\"Video saved to: {download_path}\") #\n","            else: #\n","                print(\"Failed to download the video file.\") #\n","            return #\n","        if content_type == 'file': #\n","            print(\"Processing individual file...\") #\n","            success = process_single_file_bunkr(url, headers, download_path) #\n","            if success: #\n","                print(\"\\nFile download completed!\") #\n","                print(f\"Video saved to: {download_path}\") #\n","            else: #\n","                print(\"Failed to download the video file.\") #\n","            return #\n","\n","        media_items = [] #\n","        domains = ['bunkr.ru', 'bunkr.is', 'bunkr.to', 'bunkr.la'] #\n","        api_data_found = False #\n","        for domain in domains: #\n","            if api_data_found: break #\n","            api_url = f\"https://{domain}/api/album/{content_id}\" #\n","            try: #\n","                print(f\"Attempting to fetch album data from API: {api_url}\") #\n","                api_response = requests.get(api_url, headers=headers, timeout=10) #\n","                if api_response.status_code == 200: #\n","                    try: #\n","                        api_data = api_response.json() #\n","                        if 'files' in api_data: #\n","                            print(\"Successfully retrieved album data from API\") #\n","                            for file_item in api_data['files']: #\n","                                if 'name' in file_item and 'url' in file_item: #\n","                                    file_name = file_item['name'].lower() #\n","                                    if any(file_name.endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                                        media_items.append({'url': file_item['url'], 'name': file_item['name']}) #\n","                            if media_items: #\n","                                print(f\"Found {len(media_items)} video files in album\") #\n","                                api_data_found = True #\n","                            else: #\n","                                print(\"No video files found in album API data\") #\n","                    except: print(\"Could not parse API response as JSON\") #\n","                else: print(f\"API request failed with status code {api_response.status_code}\") #\n","            except Exception as e: print(f\"Error accessing API: {e}\") #\n","\n","        if not media_items: #\n","            print(\"API approach failed, falling back to web scraping...\") #\n","            for domain in domains: #\n","                if media_items: break #\n","                album_url = f\"https://{domain}/a/{content_id}\" #\n","                try: #\n","                    print(f\"Trying album URL: {album_url}\") #\n","                    response = requests.get(album_url, headers=headers, timeout=15) #\n","                    if response.status_code != 200: #\n","                        print(f\"Error: Album page returned status code {response.status_code}\") #\n","                        continue #\n","                    soup = BeautifulSoup(response.text, 'html.parser') #\n","                    scripts = soup.find_all('script') #\n","                    for script in scripts: #\n","                        if script.string: #\n","                            if 'window.__NUXT__' in script.string: #\n","                                try: #\n","                                    start_idx = script.string.find('window.__NUXT__') + len('window.__NUXT__ = ') #\n","                                    json_str = script.string[start_idx:] #\n","                                    data = json.loads(json_str) #\n","                                    if 'state' in data and 'albums' in data['state']: #\n","                                        for album_key, album_info in data['state']['albums'].items(): #\n","                                            if 'medias' in album_info: #\n","                                                for media in album_info['medias']: #\n","                                                    if 'streamUrl' in media: #\n","                                                        name = media.get('name', f\"file_{media.get('id', len(media_items))}\") #\n","                                                        if any(name.lower().endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                                                            media_items.append({'url': media['streamUrl'],'name': name}) #\n","                                        print(f\"Found {len(media_items)} video files in NUXT data\") #\n","                                except Exception as e: print(f\"Error parsing NUXT data: {e}\") #\n","                            elif '__INITIAL_STATE__' in script.string: #\n","                                try: #\n","                                    pattern = r'__INITIAL_STATE__\\s*=\\s*(\\{.*?\\});' #\n","                                    match = re.search(pattern, script.string, re.DOTALL) #\n","                                    if match: #\n","                                        state_data = json.loads(match.group(1)) #\n","                                        if 'album' in state_data and 'files' in state_data['album']: #\n","                                            for file_item in state_data['album']['files']: #\n","                                                if 'name' in file_item and 'url' in file_item: #\n","                                                    name = file_item['name'] #\n","                                                    if any(name.lower().endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                                                        media_items.append({'url': file_item['url'], 'name': name}) #\n","                                            print(f\"Found {len(media_items)} video files in INITIAL_STATE data\") #\n","                                except Exception as e: print(f\"Error parsing INITIAL_STATE data: {e}\") #\n","                            file_urls = re.findall(r'(https?://[^\"\\']*(?:\\.mp4|\\.webm|\\.mov|\\.avi|\\.mkv))', script.string) #\n","                            for item_url in file_urls: #\n","                                name = extract_filename_from_url_bunkr(item_url) #\n","                                media_items.append({'url': item_url, 'name': name}) #\n","                    if not media_items: #\n","                        print(\"Looking for media elements in HTML...\") #\n","                        grid_items = soup.select('.grid-item a, .media-item a, .gallery-item a') #\n","                        for item in grid_items: #\n","                            href = item.get('href') #\n","                            if href and ('/d/' in href or '/v/' in href): #\n","                                item_url = f\"https://{domain}{href}\" if not href.startswith('http') else href #\n","                                item_name = item.text.strip() or extract_filename_from_url_bunkr(href) #\n","                                if any(ext in href.lower() for ext in ['/v/', '.mp4', '.webm', '.mov']): #\n","                                    media_items.append({'url': item_url, 'name': item_name}) #\n","                        media_elements = soup.select('video source, a.download-link') #\n","                        for elem in media_elements: #\n","                            src = elem.get('src') or elem.get('href') #\n","                            if src: #\n","                                if not src.startswith('http'): src = f\"https://{domain}{src}\" #\n","                                name = extract_filename_from_url_bunkr(src) #\n","                                media_items.append({'url': src, 'name': name}) #\n","                        if not media_items: #\n","                            print(\"Last resort: checking all links for video content...\") #\n","                            links = soup.find_all('a') #\n","                            for link_item in links: #\n","                                href = link_item.get('href') #\n","                                if href and ('/v/' in href): #\n","                                    item_url = f\"https://{domain}{href}\" if not href.startswith('http') else href #\n","                                    item_name = link_item.text.strip() or extract_filename_from_url_bunkr(href) #\n","                                    media_items.append({'url': item_url, 'name': item_name}) #\n","                except Exception as e: print(f\"Error during web scraping with {domain}: {e}\") #\n","\n","        seen_urls = set() #\n","        unique_media_items = [] #\n","        for item in media_items: #\n","            if item['url'] not in seen_urls: #\n","                seen_urls.add(item['url']) #\n","                unique_media_items.append(item) #\n","        media_items = unique_media_items #\n","\n","        if not media_items: #\n","            print(\"No video files found in the album or unable to parse the album page.\") #\n","            print(\"Attempting direct API approach for individual files...\") #\n","            for domain in domains: #\n","                if media_items: break #\n","                try: #\n","                    direct_api_url = f\"https://{domain}/api/files/album/{content_id}\" #\n","                    print(f\"Trying direct API: {direct_api_url}\") #\n","                    api_response = requests.get(direct_api_url, headers=headers, timeout=10) #\n","                    if api_response.status_code == 200: #\n","                        try: #\n","                            file_data = api_response.json() #\n","                            if isinstance(file_data, list) and len(file_data) > 0: #\n","                                for file_item in file_data: #\n","                                    if 'name' in file_item and 'url' in file_item: #\n","                                        name = file_item['name'] #\n","                                        if any(name.lower().endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                                            media_items.append({'url': file_item['url'], 'name': name}) #\n","                                print(f\"Found {len(media_items)} video files through direct API approach\") #\n","                        except: print(\"Failed to parse direct API response\") #\n","                except Exception as e: print(f\"Error with direct API approach using {domain}: {e}\") #\n","            if not media_items: #\n","                 print(\"No video files found in the album after all attempts.\") #\n","                 return #\n","\n","        print(f\"Found {len(media_items)} video files to download.\") #\n","        downloaded_count = 0 #\n","        for i, item in enumerate(media_items, 1): #\n","            file_url = item['url'] #\n","            file_name = item['name'] #\n","            if not file_name or file_name.isspace(): file_name = extract_filename_from_url_bunkr(file_url) #\n","            if not any(file_name.lower().endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.avi', '.mkv']): #\n","                print(f\"Skipping {file_name}: Not a video file\") #\n","                continue #\n","            if '/d/' in file_url or '/v/' in file_url or '/i/' in file_url: #\n","                download_url = get_direct_download_url_bunkr(file_url, headers) #\n","                if download_url: file_url = download_url #\n","                else: #\n","                    print(f\"Skipping {file_name}: Could not get direct download URL\") #\n","                    continue #\n","            print(f\"\\nDownloading video {i}/{len(media_items)}: {file_name}\") #\n","            if download_file_bunkr(file_url, file_name, download_path, headers): downloaded_count += 1 #\n","        if downloaded_count > 0: #\n","            print(f\"\\nDownload summary: Successfully downloaded {downloaded_count} of {len(media_items)} videos.\") #\n","            print(f\"Videos saved to: {download_path}\") #\n","        else: print(\"\\nFailed to download any videos from this album.\") #\n","    except Exception as e: print(f\"Unexpected error during download process: {e}\") #\n","\n","\n","# Function c: m3u8 Downloader\n","def download_with_m3u8(m3u8_link, download_location_file): #\n","    print(f\"Starting m3u8 download for: {m3u8_link}\")\n","    # Ensure the directory for the download_location_file exists\n","    file_dir = os.path.dirname(download_location_file)\n","    if file_dir and not os.path.exists(file_dir):\n","        os.makedirs(file_dir, exist_ok=True)\n","        print(f\"Created directory for m3u8 download: {file_dir}\")\n","\n","    # The command uses `~/.local/bin/downloadm3u8` which might not be in PATH for subprocess\n","    # A more robust way is to ensure the command is found or specify its full path if known\n","    # For Colab, `~/.local/bin` is usually in PATH for shell commands started with `!`\n","    # but for subprocess, it might be different.\n","    command = f'~/.local/bin/downloadm3u8 -o \"{download_location_file}\" \"{m3u8_link}\"' #\n","    try:\n","        process = subprocess.Popen(command, shell=True, executable='/bin/bash', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","        stdout, stderr = process.communicate()\n","        if process.returncode == 0:\n","            print(f\"m3u8 download successful! File saved as: {download_location_file}\")\n","            print(f\"Stdout: {stdout.decode()}\")\n","        else:\n","            print(\"m3u8 download failed.\")\n","            print(f\"Stderr: {stderr.decode()}\")\n","            print(f\"Stdout: {stdout.decode()}\")\n","    except Exception as e:\n","        print(f\"An error occurred during m3u8 download: {e}\")\n","\n","# Function d: Bunkr Downloader (yt-dlp)\n","def download_bunkr_with_yt_dlp(bunkr_video_url, output_folder_path): #\n","    print(f\"Starting Bunkr (yt-dlp) download for: {bunkr_video_url}\")\n","    os.makedirs(output_folder_path, exist_ok=True) #\n","    cmd = [ #\n","        \"yt-dlp\",\n","        \"--user-agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\", #\n","        \"--add-header\", \"Referer: https://bunkr.is/\", #\n","        \"--add-header\", \"Accept-Language: en-US,en;q=0.9\", #\n","        \"--no-check-certificate\", #\n","        \"--progress\", #\n","        \"--newline\", #\n","        \"--console-title\", #\n","        bunkr_video_url, #\n","        \"-o\", f\"{output_folder_path}/%(title)s.%(ext)s\" #\n","    ]\n","    try:\n","        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True) #\n","        for line in process.stdout: #\n","            print(line, end=\"\") #\n","        process.wait() #\n","        if process.returncode == 0: #\n","            print(f\"\\n✅ yt-dlp Bunkr download complete! Check your folder: {output_folder_path}\\n\") #\n","        else: #\n","            print(\"\\n❌ yt-dlp Bunkr download failed. Check the URL and try again.\\n\") #\n","    except FileNotFoundError:\n","        print(\"Error: yt-dlp command not found. Make sure it's installed and in your PATH.\")\n","    except Exception as e:\n","        print(f\"An error occurred during yt-dlp Bunkr download: {e}\")\n","\n","\n","# --- Control Structure for Downloading ---\n","if not url:\n","    print(\"Error: URL is not provided. Please specify a URL in Cell 2.\")\n","else:\n","    # Ensure output_path is a directory for functions that expect a directory\n","    # For m3u8, output_path is treated as a full file path if the user intends so,\n","    # otherwise, they should provide a directory.\n","    # For simplicity, we'll assume output_path from Cell 2 is the directory.\n","    # Specific file naming will be handled within each function.\n","\n","    # For m3u8, if user provides a directory in output_path, we need a filename.\n","    # If output_path looks like a file, we use it directly for m3u8.\n","    m3u8_output_file = output_path\n","    if download_type == 'c':\n","        if os.path.isdir(output_path) or not '.' in os.path.basename(output_path): # Heuristic: if it's a dir or no extension\n","             # Try to get a filename from URL or use a default for m3u8\n","            parsed_m3u8_url = urlparse(url)\n","            m3u8_filename_from_url = os.path.basename(parsed_m3u8_url.path)\n","            if m3u8_filename_from_url and '.' in m3u8_filename_from_url:\n","                 # replace m3u8 extension with mp4 or ts\n","                base, ext = os.path.splitext(m3u8_filename_from_url)\n","                output_filename = base + \".mp4\" # Defaulting to mp4\n","            else:\n","                output_filename = \"downloaded_video.mp4\" # Default filename\n","            m3u8_output_file = os.path.join(output_path.strip(os.sep), output_filename) #\n","        # else: m3u8_output_file is already the full path from Cell 2\n","\n","    if download_type == 'a': #\n","        # wget -P expects a directory. output_path is already a directory path.\n","        download_with_wget(url, output_path.strip(os.sep))\n","    elif download_type == 'b': #\n","        # download_bunkr_content_custom expects a directory path.\n","        download_bunkr_content_custom(url, output_path.strip(os.sep))\n","    elif download_type == 'c': #\n","        # download_with_m3u8 expects the full output file path.\n","        download_with_m3u8(url, m3u8_output_file)\n","    elif download_type == 'd': #\n","        # download_bunkr_with_yt_dlp expects a directory path.\n","        download_bunkr_with_yt_dlp(url, output_path.strip(os.sep))\n","    else:\n","        print(f\"Error: Invalid download_type '{download_type}'. Please choose from 'a', 'b', 'c', or 'd'.\")\n","\n"],"metadata":{"cellView":"form","id":"9athjIckWKwR"},"id":"9athjIckWKwR","execution_count":null,"outputs":[]}]}